{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 4, Problem 4 Classification on real data\n",
    "\n",
    "ECE C143A/C243A, Spring Quarter 2020, Prof. J.C. Kao, TAs J. Lee, T. Monsoor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "Neural prosthetic systems can be built based on classifying neural activity related to planning. As described in class, this is analogous to mapping patterns of neural activity to keys on a keyboard.\n",
    "In this problem, we will apply the results of Problems 1 and 2 to real neural data. The neural data were recorded using a 100-electrode array in premotor cortex of a macaque monkey1. The dataset can be found on CCLE as `ps4_realdata.mat`.\n",
    "\n",
    "The following describes the data format. The `.mat` file is loaded into Python as a dictionary with two keys: `train_trial` contains the training data and `test_trial` contains the test data. Each of these contains spike trains recorded simultaneously from 97 neurons while the monkey reached 91 times along each of 8 different reaching angles.\n",
    "\n",
    "The spike train recorded from the $i_{th}$ neuron on the $n_{th}$ trial of the $k_{th}$ reaching angle is accessed as \n",
    "\n",
    "`data['train_trial'][n,k][1][i,:]`\n",
    "\n",
    "where n = 0,...,90, k = 0,...,7, and i = 0, . . . , 96.  The [1] in between [n,k] and [i,:] does not mean anything for this assignment and is simply an \"artifact\" of how the data is structured. A spike train is represented as a sequence of zeros and ones, where time is discretized in 1 ms steps. A zero indicates that the neuron did not spike in the 1 ms bin, whereas a one indicates that the neuron spiked once in the 1 ms bin. The structure test trial has the same format as train trial.\n",
    "\n",
    "Each spike train is 700 ms long (and thus represented by an array of length 700).  This comprises a 200ms baseline period (before the reach target turned on), a 500ms planning period (after the reach target turned on).  Because it takes time for information about the reach target to arrive in premotor cortex (due to the time required for action potentials to propagate and for visual processing), we will ignore the first 150ms of the planning period.  *** FOR THIS PROBLEM, we will take spike counts for each neuron within a single 200ms bin starting 150ms after the reach target turns on. ***\n",
    "\n",
    "In other words, to calculate firing rates, you will calculate it over the 200ms window: \n",
    "\n",
    "`data['train_trial'][n,k][1][i,350:550]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.matlib as npm\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.special\n",
    "import scipy.io as sio\n",
    "import math\n",
    "\n",
    "data = sio.loadmat('ps4_realdata.mat') # load the .mat file.\n",
    "NumTrainData = data['train_trial'].shape[0]\n",
    "NumClass = data['train_trial'].shape[1]\n",
    "NumTestData = data['test_trial'].shape[0]\n",
    "\n",
    "# Reloading any code written in external .py files.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) (8 points) \n",
    "Fit the ML parameters of model i) to the training data (91 × 8 observations of a length 97 array of neuron firing rates). \n",
    "\n",
    "To calculate the firing rates, use a single 200ms bin starting from 150ms after the target turns on.  This corresponds to using `data['train_trial'][n,k][1][i, 350:550]` to calculate all firing rates.  This corresponds to a 200ms window that turns on 150ms after the reach turns on.\n",
    "\n",
    "Then, use these parameters to classify the test data (91 × 8 data points) according to the decision rule (1). What is the percent of test data points correctly classified?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is our accuracy of classified test data points: 96.02%\n"
     ]
    }
   ],
   "source": [
    "##4a\n",
    "\n",
    "# Calculate the firing rates.\n",
    "TrainData = data[\"train_trial\"]\n",
    "TestData = data[\"test_trial\"]\n",
    "\n",
    "# Contains the firing rates for all neurons on all 8 x 91 trials\n",
    "trainDataArr =  np.zeros((NumClass,NumTrainData,97)) \n",
    "testDataArr =  np.zeros((NumClass,NumTestData,97))\n",
    "bin_width = 0.2 #200 ms bin\n",
    "\n",
    "for classIX in range(NumClass):\n",
    "    for trainDataIX in range(NumTrainData):   \n",
    "        total_train = np.sum(data['train_trial'][trainDataIX,classIX][1][:,350:550],1)\n",
    "        trainDataArr[classIX,trainDataIX,:] = total_train / bin_width\n",
    "    for testDataIX in range(NumTestData):  \n",
    "        total_test = np.sum(data['test_trial'][testDataIX,classIX][1][:,350:550],1)\n",
    "        testDataArr[classIX,testDataIX,:] = total_test / bin_width\n",
    "#====================================================#\n",
    "# YOUR CODE HERE:\n",
    "#   Fit the ML parameters of model i) to training data\n",
    "#====================================================#\n",
    "# Class Prior Calculations\n",
    "trainParam1 = {} # Dictionary for Gaussian shared covariance\n",
    "training_prior = float(NumTrainData) / (NumClass * NumTrainData)\n",
    "trainParam1[\"pi\"] = np.array([training_prior for i in range(NumClass)])\n",
    "\n",
    "# Mean and Covariance Calculations\n",
    "neuron_num = trainDataArr.shape[2] # Extracts number of neurons\n",
    "trainmu_param1 = np.zeros((NumClass, neuron_num)) # Holds means of all data\n",
    "\n",
    "# n holds our class specific data, trained_shared_cov our class covariances\n",
    "n = np.zeros((neuron_num, NumTrainData)) # A 97 x 91 matrix for each class\n",
    "trained_shared_cov = np.zeros((neuron_num, neuron_num)) # A 97 x 97 matrix\n",
    "\n",
    "for classIX in range(NumClass): \n",
    "    for neuron in range(neuron_num):\n",
    "        neuron_data = trainDataArr[classIX][:, neuron]\n",
    "        n[neuron] = neuron_data\n",
    "        \n",
    "        neuron_mu = np.mean(neuron_data)\n",
    "        trainmu_param1[classIX][neuron] = neuron_mu\n",
    "        pass\n",
    "    trained_shared_cov += np.cov(n)\n",
    "    pass\n",
    "\n",
    "trainParam1[\"mean\"] = trainmu_param1\n",
    "trainParam1[\"cov\"] = trained_shared_cov / NumClass\n",
    "\n",
    "# Gather model i) parameters\n",
    "sig_inv_shared = np.linalg.inv(trainParam1[\"cov\"])\n",
    "c = -1.0 / 2 # Common constant\n",
    "\n",
    "# Retrieve parameters for each class\n",
    "w_k_params = np.zeros((NumClass, 1, neuron_num)) # Stores w_k values\n",
    "w_k_consts = np.zeros((NumClass))\n",
    "\n",
    "for classIX in range(NumClass):\n",
    "    class_mu = trainParam1[\"mean\"][classIX] # Retrieve class mean\n",
    "    \n",
    "    w_k = sig_inv_shared.dot(class_mu)\n",
    "    w_k_params[classIX] = w_k\n",
    "    \n",
    "    w_const = c * ((class_mu.T).dot(sig_inv_shared)).dot(class_mu)\n",
    "    w_k_consts[classIX] = w_const\n",
    "    pass\n",
    "#====================================================#\n",
    "# END YOUR CODE\n",
    "#====================================================# \n",
    "\n",
    "#====================================================#\n",
    "# YOUR CODE HERE:\n",
    "#   Classify the test data and print the accuracy\n",
    "#====================================================#\n",
    "# Classify test data, total of 8 x 91 trials\n",
    "error_total = 0 # Keeps track of erroneously classified trials\n",
    "total = NumClass * NumTestData\n",
    "\n",
    "for classIX in range(NumClass):\n",
    "    for dataIX in range(NumTestData):\n",
    "        inputs = testDataArr[classIX][dataIX]\n",
    "        \n",
    "        # Calculate alpha(x) for all classes\n",
    "        z_1 = (w_k_params[0][0].T).dot(inputs) + w_k_consts[0]\n",
    "        z_2 = (w_k_params[1][0].T).dot(inputs) + w_k_consts[1]\n",
    "        z_3 = (w_k_params[2][0].T).dot(inputs) + w_k_consts[2]\n",
    "        z_4 = (w_k_params[3][0].T).dot(inputs) + w_k_consts[3]\n",
    "        z_5 = (w_k_params[4][0].T).dot(inputs) + w_k_consts[4]\n",
    "        z_6 = (w_k_params[5][0].T).dot(inputs) + w_k_consts[5]\n",
    "        z_7 = (w_k_params[6][0].T).dot(inputs) + w_k_consts[6]\n",
    "        z_8 = (w_k_params[7][0].T).dot(inputs) + w_k_consts[7]\n",
    "        \n",
    "        # Obtain the classified class number\n",
    "        probs = [z_1, z_2, z_3, z_4, z_5, z_6, z_7, z_8]\n",
    "        classified_num = probs.index(max(probs)) # Get the classified class\n",
    "        \n",
    "        # if the class is incorrectly classified, add 1 to the error number\n",
    "        if (classified_num != classIX):\n",
    "            error_total += 1\n",
    "            pass\n",
    "        pass\n",
    "    pass\n",
    "\n",
    "# Display our accuracy\n",
    "msg = \"This is our accuracy of classified test data points: \"\n",
    "accuracy = \"{:.2f}\".format((float(total - error_total) / total) * 100.0)\n",
    "print(msg + accuracy + \"%\")\n",
    "#====================================================#\n",
    "# END YOUR CODE\n",
    "#====================================================# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question:\n",
    "What is the percent of test data points correctly classified?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer: 96.02% of the test data points are correctly classified.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) (6 points) \n",
    "Repeat part (a) for model ii). You `should encounter a Python error` when classifying the test data. What is this error? Why did the Python error occur? What would we need to do to correct this error?\n",
    "\n",
    "To be concrete, the output of this cell should be a `Python error` and that's all fine.  But we want you to understand what the error is so we can fix it later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-363279097d76>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mclassIX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNumClass\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mclass_mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainParam2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"mean\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclassIX\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0msig_inv_specific\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainParam2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"cov\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclassIX\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mw_k\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msig_inv_specific\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_mu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36minv\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36minv\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m    545\u001b[0m     \u001b[0msignature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'D->D'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'd->d'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m     \u001b[0mainv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mainv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_singular\u001b[1;34m(err, flag)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Singular matrix\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_raise_linalgerror_nonposdef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "##4b\n",
    "\n",
    "#====================================================#\n",
    "# YOUR CODE HERE:\n",
    "# Fit the ML parameters of model ii) to training data\n",
    "#====================================================#\n",
    "# Calculate class specific covariances\n",
    "trainParam2 = {} # Dictionary for Gaussian specific covariance\n",
    "trainParam2[\"pi\"] = trainParam1[\"pi\"]\n",
    "trainParam2[\"mean\"] = trainParam1[\"mean\"]\n",
    "\n",
    "# Specific Covariance Calculations\n",
    "n1 = np.zeros((NumClass, 97, 97)) # 8 x 97 x 97 for all covariances\n",
    "trained_specific_cov = np.zeros((neuron_num, NumTrainData)) # A 97 x 91 matrix\n",
    "\n",
    "for classIX in range(NumClass):\n",
    "    for neuron in range(neuron_num):\n",
    "        trained_specific_cov[neuron] = trainDataArr[classIX][:, neuron]\n",
    "        pass\n",
    "    cov_specific = np.cov(trained_specific_cov)\n",
    "    n1[classIX, :] = cov_specific\n",
    "    pass\n",
    "\n",
    "trainParam2[\"cov\"] = n1\n",
    "\n",
    "w_k_params = np.zeros((NumClass, 1, neuron_num))\n",
    "w_k_consts = np.zeros((NumClass))\n",
    "\n",
    "for classIX in range(NumClass):\n",
    "    class_mu = trainParam2[\"mean\"][classIX]\n",
    "    sig_inv_specific = np.linalg.inv(trainParam2[\"cov\"][classIX])\n",
    "\n",
    "    w_k = sig_inv_specific.dot(class_mu)\n",
    "    w_k_params[classIX] = w_k\n",
    "    \n",
    "    w_const = c * ((class_mu.T).dot(sig_inv_specific)).dot(class_mu)\n",
    "    w_k_consts[classIX] = w_const\n",
    "    pass\n",
    "# Did not code anything after this, because this is where the error occurred\n",
    "#====================================================#\n",
    "# END YOUR CODE\n",
    "#====================================================# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question:\n",
    "Why did the python error occur? What would we need to do to correct this error?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer:  The python error occurred because we were attempting to take the inversion of a not full-rank matrix (i.e. for one class it was a 97 x 97 matrix but our rank was only 90). This by definition means the matrix is not invertible. To correct this, we can remove rows that are all zeros in order to get a full rank matrix, in which case we would be able to take the determinant of thereafter. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) (8 points) \n",
    "Correct the problem from part (b) by detecting and then removing offending neurons that cause the error. Now, what is the percent of test data points correctly classified? Is it higher or lower than your answer to part (a)? Why might this be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is our accuracy of classified test data points: 44.09%\n"
     ]
    }
   ],
   "source": [
    "neuronsToRemove = []\n",
    "#====================================================#\n",
    "# YOUR CODE HERE:\n",
    "#   Detect and then remove the offending neurons, so that \n",
    "#   you no longer run into the bug in part (b).\n",
    "#====================================================#\n",
    "# Iterate through our data, finding our erroneous neurons\n",
    "for classIX in range(NumClass):\n",
    "    for neuron in range(neuron_num):\n",
    "        access = trainDataArr[classIX][:, neuron]\n",
    "        \n",
    "        # If the neuron never fires in a class, append to neuronsToRemove\n",
    "        if (all(access == 0) and (neuron not in neuronsToRemove)):\n",
    "            neuronsToRemove.append(neuron)\n",
    "            pass\n",
    "        pass\n",
    "    pass\n",
    "neuronsToRemove.sort() # Sort the list from least to greatest\n",
    "err_n = len(neuronsToRemove) # Number of defective neurons\n",
    "#====================================================#\n",
    "# END YOUR CODE\n",
    "#====================================================# \n",
    "\n",
    "#====================================================#\n",
    "# YOUR CODE HERE:\n",
    "# Fit the ML parameters,classify the test data and print the accuracy\n",
    "#====================================================#\n",
    "# Calculate new means and covariances\n",
    "new_specificov = np.zeros((NumClass, neuron_num - err_n, neuron_num - err_n))\n",
    "new_specificlass = np.zeros((neuron_num - err_n, NumTrainData)) \n",
    "trainmu_param2 = np.zeros((NumClass, neuron_num - err_n))\n",
    "\n",
    "for classIX in range(NumClass):\n",
    "    counter = 0 # Index counter to account for defective neurons\n",
    "    for neuron in range(neuron_num):\n",
    "        if (neuron not in neuronsToRemove):\n",
    "            valid_data = trainDataArr[classIX][:, neuron]\n",
    "            new_specificlass[counter, :] = valid_data\n",
    "            \n",
    "            trainmu_param2[classIX][counter] = np.mean(valid_data)\n",
    "            counter += 1\n",
    "            pass\n",
    "        pass\n",
    "    new_specificov[classIX, :] = np.cov(new_specificlass)\n",
    "    pass\n",
    "trainParam2[\"cov\"] = new_specificov\n",
    "trainParam2[\"mean\"] = trainmu_param2\n",
    "\n",
    "# Retrieve the parameters\n",
    "w_k_params = np.zeros((NumClass, 1, neuron_num - err_n))\n",
    "w_k_consts = np.zeros((NumClass))\n",
    "\n",
    "for classIX in range(NumClass):\n",
    "    class_mu = trainParam2[\"mean\"][classIX]\n",
    "    sig_inv_specific = np.linalg.inv(trainParam2[\"cov\"][classIX])\n",
    "    \n",
    "    w_k_params[classIX] = w_k = sig_inv_specific.dot(class_mu)\n",
    "    \n",
    "    w_const = c * ((class_mu.T).dot(sig_inv_specific)).dot(class_mu)\n",
    "    w_const += c * np.log(np.linalg.det(trainParam2[\"cov\"][classIX]))\n",
    "    w_k_consts[classIX] = w_const\n",
    "    pass\n",
    "\n",
    "# Classify test data, total of 8 x 91 trials\n",
    "error_total = 0 # Keeps track of erroneously classified trials\n",
    "total = NumClass * NumTestData # Total number of trials\n",
    "\n",
    "for classIX in range(NumClass):\n",
    "    for dataIX in range(NumTestData):\n",
    "        inputs = np.zeros((0))\n",
    "        \n",
    "        for neuron in range(neuron_num):\n",
    "            if (neuron not in neuronsToRemove):\n",
    "                inputs = np.append(inputs, testDataArr[classIX][dataIX][neuron])\n",
    "                pass\n",
    "            pass\n",
    "        \n",
    "        # Calculate quadratic terms\n",
    "        quad1 = (inputs.T).dot(np.linalg.inv(trainParam2[\"cov\"][0]))\n",
    "        quad1 = quad1.dot(inputs)\n",
    "        \n",
    "        quad2 = (inputs.T).dot(np.linalg.inv(trainParam2[\"cov\"][1]))\n",
    "        quad2 = quad2.dot(inputs)\n",
    "        \n",
    "        quad3 = (inputs.T).dot(np.linalg.inv(trainParam2[\"cov\"][2]))\n",
    "        quad3 = quad3.dot(inputs)\n",
    "        \n",
    "        quad4 = (inputs.T).dot(np.linalg.inv(trainParam2[\"cov\"][3]))\n",
    "        quad4 = quad4.dot(inputs)\n",
    "        \n",
    "        quad5 = (inputs.T).dot(np.linalg.inv(trainParam2[\"cov\"][4]))\n",
    "        quad5 = quad5.dot(inputs)\n",
    "        \n",
    "        quad6 = (inputs.T).dot(np.linalg.inv(trainParam2[\"cov\"][5]))\n",
    "        quad6 = quad6.dot(inputs)\n",
    "        \n",
    "        quad7 = (inputs.T).dot(np.linalg.inv(trainParam2[\"cov\"][6]))\n",
    "        quad7 = quad7.dot(inputs)\n",
    "        \n",
    "        quad8 = (inputs.T).dot(np.linalg.inv(trainParam2[\"cov\"][7]))\n",
    "        quad8 = quad8.dot(inputs)\n",
    "        \n",
    "        # Calculate alpha(x) for all classes\n",
    "        z_1 = (w_k_params[0][0].T).dot(inputs) + w_k_consts[0] + c * quad1\n",
    "        z_2 = (w_k_params[1][0].T).dot(inputs) + w_k_consts[1] + c * quad2\n",
    "        z_3 = (w_k_params[2][0].T).dot(inputs) + w_k_consts[2] + c * quad3\n",
    "        z_4 = (w_k_params[3][0].T).dot(inputs) + w_k_consts[3] + c * quad4\n",
    "        z_5 = (w_k_params[4][0].T).dot(inputs) + w_k_consts[4] + c * quad5\n",
    "        z_6 = (w_k_params[5][0].T).dot(inputs) + w_k_consts[5] + c * quad6\n",
    "        z_7 = (w_k_params[6][0].T).dot(inputs) + w_k_consts[6] + c * quad7\n",
    "        z_8 = (w_k_params[7][0].T).dot(inputs) + w_k_consts[7] + c * quad8\n",
    "        \n",
    "        # Obtain the classified class number\n",
    "        probs = [z_1, z_2, z_3, z_4, z_5, z_6, z_7, z_8]\n",
    "        classified_num = probs.index(max(probs))\n",
    "        \n",
    "        if (classified_num != classIX):\n",
    "            error_total += 1\n",
    "            pass\n",
    "        pass\n",
    "    pass\n",
    "\n",
    "# Display our accuracy\n",
    "msg = \"This is our accuracy of classified test data points: \"\n",
    "accuracy = \"{:.2f}\".format((float(total - error_total) / total) * 100.0)\n",
    "print(msg + accuracy + \"%\")\n",
    "#====================================================#\n",
    "# END YOUR CODE\n",
    "#====================================================# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question:\n",
    "What is the percent of test data points correctly classified? Is it higher or lower than your answer to part (a)? Why might this be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer:  44.09% of the test data points are correctly classified. It is definitely lower than my answer to part (a). One reason for this drop in accuracy is that by removing non-firing neurons, we are reducing the size of our training set, meaning our model will be less accurate (the larger the training set, the more stable our predictions will be), thus making it more susceptible to influence from small variance neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) (8 points) \n",
    "Now we classify using a naive Bayes model. Repeat part (a) for model iii). Keep the convention in part (c), where offending neurons were removed from the anal- ysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is our accuracy of classified test data points: 92.03%\n"
     ]
    }
   ],
   "source": [
    "##4d\n",
    "#====================================================#\n",
    "# YOUR CODE HERE:\n",
    "# Fit the ML parameters,classify the test data and print the accuracy\n",
    "#====================================================#\n",
    "trainParam3 = {} # Dictionary for Poisson distribution\n",
    "trainParam3[\"pi\"] = trainParam2[\"pi\"]\n",
    "trainParam3[\"mean\"] = trainParam2[\"mean\"]\n",
    "\n",
    "poiss_error_total = 0 # Keeps track of erroneously classified trials\n",
    "total = NumClass * NumTestData # Total number of trials\n",
    "\n",
    "for classIX in range(NumClass):\n",
    "    for dataIX in range(NumTestData):\n",
    "        inputs = np.zeros((0))\n",
    "        for neuron in range(neuron_num):\n",
    "            if (neuron not in neuronsToRemove):\n",
    "                inputs = np.append(inputs, testDataArr[classIX][dataIX][neuron])\n",
    "                pass\n",
    "            pass\n",
    "        \n",
    "        # Retrieve Poisson parameters\n",
    "        poissmean1 = trainParam3[\"mean\"][0]\n",
    "        poissmean2 = trainParam3[\"mean\"][1]\n",
    "        poissmean3 = trainParam3[\"mean\"][2]\n",
    "        poissmean4 = trainParam3[\"mean\"][3]\n",
    "        poissmean5 = trainParam3[\"mean\"][4]\n",
    "        poissmean6 = trainParam3[\"mean\"][5]\n",
    "        poissmean7 = trainParam3[\"mean\"][6]\n",
    "        poissmean8 = trainParam3[\"mean\"][7]\n",
    "\n",
    "        # Calculate alpha(x) for all classes\n",
    "        z_1 = inputs.dot(np.log(poissmean1))\n",
    "        z_2 = inputs.dot(np.log(poissmean2))\n",
    "        z_3 = inputs.dot(np.log(poissmean3))\n",
    "        z_4 = inputs.dot(np.log(poissmean4))\n",
    "        z_5 = inputs.dot(np.log(poissmean5))\n",
    "        z_6 = inputs.dot(np.log(poissmean6))\n",
    "        z_7 = inputs.dot(np.log(poissmean7))\n",
    "        z_8 = inputs.dot(np.log(poissmean8))\n",
    "            \n",
    "        for i in range(neuron_num - err_n): # Subtract lambda_{ki}\n",
    "            z_1 -= poissmean1[i]\n",
    "            z_2 -= poissmean2[i]\n",
    "            z_3 -= poissmean3[i]\n",
    "            z_4 -= poissmean4[i]\n",
    "            z_5 -= poissmean5[i]\n",
    "            z_6 -= poissmean6[i]\n",
    "            z_7 -= poissmean7[i]\n",
    "            z_8 -= poissmean8[i]\n",
    "        \n",
    "        # Obtain the classified class number\n",
    "        probs = [z_1, z_2, z_3, z_4, z_5, z_6, z_7, z_8]\n",
    "        classified_num = probs.index(max(probs))\n",
    "        \n",
    "        # If the class is incorrectly classified, add 1 to the error number\n",
    "        if (classified_num != classIX):\n",
    "            poiss_error_total += 1\n",
    "            pass\n",
    "        pass\n",
    "    pass\n",
    "\n",
    "# Display our accuracy\n",
    "msg = \"This is our accuracy of classified test data points: \"\n",
    "accuracy = \"{:.2f}\".format((float(total - poiss_error_total) / total) * 100.0)\n",
    "print(msg + accuracy + \"%\")\n",
    "        \n",
    "#====================================================#\n",
    "# END YOUR CODE\n",
    "#====================================================# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question:\n",
    "what is the percent of test data points correctly classified? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer: 92.03% of the test data points are correctly classified.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
